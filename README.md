# Dev,BigData et IA Portfolio - NDONGO Mamoudou 

Ce portfolio regroupe l'ensemble des projets que j'ai r√©alis√©s en science des donn√©es et en analyse de donn√©es dans le cadre de mes √©tudes, de mon apprentissage personnel et par passion. Il met √©galement en avant mes r√©alisations, mes comp√©tences et mes certifications, avec des mises √† jour r√©guli√®res pour refl√©ter ma progression.

#### Email :  mamoudoundongo78@gmail.com

#### Linkedin : https://www.linkedin.com/in/mamoudou-ndongo/

## R√©alisations

## Projets




<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/planet_discovery.PNG" alt="Planet Discovery System Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/planet-discovery-pipeline">
          Syst√®me de D√©couverte et d'Analyse de Plan√®tes avec Flask, Kafka, Spark, HDFS, Hive, Machine Learning et Docker
        </a>
      </strong>
      <p>
        **Ce projet Big Data et Intelligence Artificielle** consiste √† construire un pipeline complet pour la gestion, l‚Äôanalyse et la pr√©diction des caract√©ristiques des plan√®tes d√©couvertes dans l‚Äôespace. Il combine des technologies de streaming, de stockage distribu√©, de traitement de donn√©es massives et de machine learning pour cr√©er un syst√®me robuste d‚Äôanalyse et de pr√©diction.
      </p>
      <p><strong>Fonctionnalit√©s principales :</strong></p>
      <ul>
        <li>D√©veloppement d‚Äôune **API Flask** permettant de recevoir et valider les donn√©es de d√©couvertes de plan√®tes via des requ√™tes HTTP POST</li>
        <li>Conteneurisation de tous les services (Flask, Kafka, Spark, HDFS, Hive) avec **Docker** et **Docker Compose** pour une orchestration simplifi√©e</li>
        <li>Int√©gration avec **Kafka** pour la publication des donn√©es re√ßues dans un **topic** d√©di√© au streaming en temps r√©el</li>
        <li>Configuration d‚Äôun pipeline de traitement en temps r√©el avec **Apache Spark** pour consommer les messages depuis Kafka, effectuer des analyses statistiques et des transformations</li>
        <li>Calcul de m√©triques agr√©g√©es comme la r√©partition des types de plan√®tes, la moyenne des masses et la corr√©lation entre la pr√©sence d‚Äôeau et d‚Äôautres caract√©ristiques</li>
        <li>D√©veloppement d‚Äôun mod√®le de **Machine Learning** pour pr√©dire la probabilit√© d‚Äôhabitabilit√© des plan√®tes en fonction de leurs caract√©ristiques physiques et atmosph√©riques</li>
        <li>Stockage structur√© des donn√©es et des r√©sultats d‚Äôanalyses dans **HDFS** pour la persistance et dans **Hive** pour la requ√™tabilit√© via SQL</li>
        <li>Ajout d‚Äôune fonctionnalit√© dans l‚Äô**API Flask** permettant de r√©cup√©rer les donn√©es analytiques stock√©es dans HDFS et Hive et de les exposer sous forme de JSON</li>
        <li>Impl√©mentation d‚Äôune route suppl√©mentaire pour uploader directement des fichiers vers **HDFS** depuis l‚ÄôAPI Flask</li>
      </ul>
      <p><strong>Technologies utilis√©es :</strong> Flask, Kafka, Apache Spark, HDFS, Hive, Machine Learning, Hadoop, Docker, Docker Compose, Python.</p>
    </td>
  </tr>
</table>









<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/asteroid.PNG" alt="Asteroid Trajectory Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/AsteroidCollisionPrediction">
          Pr√©diction des Collisions d'Ast√©ro√Ødes avec Hadoop, Kafka, Spark et Machine Learning
        </a>
      </strong>
      <p>
        **Ce projet Big Data et Machine Learning** a pour objectif de traiter et analyser des donn√©es d'ast√©ro√Ødes en temps r√©el en utilisant un environnement distribu√© bas√© sur **Kafka**, **Hadoop (HDFS)** et **Spark**. L‚Äôobjectif principal est de pr√©dire les trajectoires des ast√©ro√Ødes et d'√©valuer leur probabilit√© de collision avec la Terre.
      </p>
      <p><strong>Fonctionnalit√©s principales :</strong></p>
      <ul>
        <li>D√©ploiement d‚Äôun environnement distribu√© avec **Kafka** pour le streaming de donn√©es en temps r√©el, **Hadoop (HDFS)** pour le stockage distribu√© et **Spark** pour le traitement des donn√©es massives</li>
        <li>G√©n√©ration de donn√©es simul√©es sur les ast√©ro√Ødes et publication continue sur un topic **Kafka**</li>
        <li>Consommation des donn√©es provenant de **Kafka** et stockage dans **HDFS** pour un traitement ult√©rieur</li>
        <li>Nettoyage et transformation des donn√©es avec **Spark** pour les pr√©parer aux analyses</li>
        <li>Analyse des trajectoires des ast√©ro√Ødes et mod√©lisation pr√©dictive avec **Machine Learning** et **Deep Learning**</li>
        <li>Utilisation de **Spark Streaming** pour les analyses temporelles et le calcul des trajectoires en temps r√©el</li>
        <li>Cr√©ation de visualisations des trajectoires des ast√©ro√Ødes et des probabilit√©s de collision avec **Apache Superset** ou **Echarts**</li>
      </ul>
      <p><strong>Technologies utilis√©es :</strong> Kafka, Hadoop (HDFS), Spark, Machine Learning, Deep Learning, Apache Superset, Echarts.</p>
    </td>
  </tr>
</table>



<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/seismic.PNG" alt="Analyse Sismique Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/seismic-data-analysis">
          Analyse et Traitement des Donn√©es Sismiques avec Hadoop, Hive et Spark
        </a>
      </strong>
      <p>
        **Ce projet Big Data** a pour objectif de traiter et analyser de grands volumes de donn√©es sismiques 
        en utilisant un environnement distribu√© bas√© sur **Hadoop, Hive et Spark**. L‚Äôobjectif principal est 
        de d√©tecter des √©v√©nements sismiques et de comprendre les tendances sismiques sur diff√©rentes p√©riodes.
      </p>
      <p><strong>Fonctionnalit√©s principales :</strong></p>
      <ul>
        <li>D√©ploiement d‚Äôun environnement **Docker** avec **Hadoop, Hive et Spark**</li>
        <li>Importation et traitement des donn√©es sismiques stock√©es sur **HDFS**</li>
        <li>Nettoyage et transformation des donn√©es avec **Spark**</li>
        <li>Analyse des √©v√©nements sismiques et d√©tection de tendances</li>
        <li>Int√©gration de **Kafka** et **Spark Streaming** pour les analyses temporelles</li>
        <li>Possibilit√© d‚Äôajouter une interface de visualisation avec **Apache Superset** ou **Echarts**</li>
      </ul>
      <p><strong>Technologies utilis√©es :</strong> Docker, Hadoop (HDFS), Hive, Spark, Kafka, Apache Superset, Echarts.</p>
    </td>
  </tr>
</table>



<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/web_scraping.PNG" alt="web scraping" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/WebScrapingCollection">
          Web Scraping Collection
        </a>
      </strong>
      <p>
        Un projet d'extraction automatis√©e de donn√©es √† partir de sites web. Il permet de collecter des informations structur√©es (produits, prix, articles, etc.) 
        de mani√®re rapide et efficace pour des analyses ou surveiller des donn√©es en temps r√©el.
      </p>
      <p><strong>Technologies utilis√©es :</strong> Python, BeautifulSoup, scrapy, Selenium, Requests, Pandas.</p>
    </td>
  </tr>
</table>






<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/G_aosis1.png" alt="GP Colis Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/gp_colis">
          GP Colis - Gestion des Colis entre le S√©n√©gal et la France
        </a>
      </strong>
      <p>
        **GP Colis** est une application web d√©di√©e √† la gestion et √† la publication d'annonces pour l'envoi ou la r√©ception de colis entre le S√©n√©gal et la France. 
        Les utilisateurs peuvent publier des annonces, consulter celles des autres, et organiser des envois de colis en utilisant une interface conviviale et responsive.
      </p>
      <p><strong>Fonctionnalit√©s principales :</strong> Cr√©ation de comptes, publication d'annonces de colis, validation des informations, affichage dynamique des villes via API.</p>
      <p><strong>Technologies utilis√©es :</strong> React.js, Node.js, Axios, API REST, Nginx (Reverse Proxy), HTML5, CSS3.</p>
    </td>
  </tr>
</table>



<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/spam.PNG" alt="Ic√¥ne d'email" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/Deep_Learning_pour_la_Classification_Binaire">
          Classification : Emails (Spam) et Cancer
        </a>
      </strong>
      <p>
        Ce d√©p√¥t regroupe deux projets exploitant des mod√®les de Deep Learning pour r√©soudre des probl√©matiques de classification binaire. 
        Le premier projet porte sur la classification d'emails, avec pour objectif d'identifier si un message est un spam ou non. 
        Le second projet se concentre sur la classification m√©dicale, visant √† pr√©dire si une personne est atteinte de cancer.
      </p>
    </td>
  </tr>
</table>



<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/finance.PNG" alt="Ic√¥ne Marketing" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/analyse-donnees_fraude-marketing">
          Analyse des Comportements d'Achat des Clients - Campagne Marketing
        </a>
      </strong>
      <p>
        Ce projet explore les comportements d'achat des clients d'une entreprise √† partir des donn√©es de campagnes marketing. L'objectif est de 
        r√©aliser une analyse exploratoire des donn√©es (EDA) pour mieux comprendre les habitudes d'achat des clients, nettoyer et pr√©parer les 
        donn√©es, puis appliquer une segmentation bas√©e sur les revenus et les d√©penses. Cette analyse est pr√©sent√©e sous forme d'un tableau de bord 
        interactif d√©velopp√© avec Streamlit, permettant d'interagir facilement avec les insights obtenus. 
      </p>
    </td>
  </tr>
</table>









                                                  
## Comp√©tences 

üìä Data Science & Machine Learning
  - M√©thodologies : Machine Learning, Deep Learning, Statistiques, Big Data Analytics, Web Scraping
  - Mod√©lisation : R√©gression, Classification, Clustering, S√©ries temporelles
  - Traitement de Donn√©es : Feature Engineering, Data Cleaning, Data Wrangling

üíª Langages de Programmation
   - Python : Pandas, NumPy, Scikit-Learn, SciPy, Keras, TensorFlow, Matplotlib, Seaborn
   - SQL : MySQL, PostgreSQL, SQLite
   - Autres : JavaScript, C++,

üìÇ Big Data & Cloud Computing
  - Big Data : Hadoop (HDFS, Hive), Spark (PySpark, Spark SQL), Kafka
  - Cloud Computing : AWS (S3, Lambda, EC2),

üåê D√©veloppement Web & API
 - Front-End : HTML5, CSS3, JavaScript (React.js)
 - Back-End : Python (Flask, FastAPI, Django)
 - Bases de Donn√©es : MySQL, PostgreSQL, MongoDB, 
 - D√©ploiement : Docker, Nginx

üìà Visualisation de Donn√©es
 - Libraries Python : Matplotlib, Seaborn, Plotly
 - BI & Dashboards : Power BI, Tableau , Streamlit

üõ°Ô∏è Soft Skills
 - R√©solution de probl√®mes
 - Communication des r√©sultats
 - Gestion de projet Agile / Scrum
 - Travail en √©quipe
  

## Certificats

  ‚Ä¢ [Certificat Python - La visualisation des donn√©es](./Certificats/CertificatDaccomplissement_Python_La_visualisation_des_donnees.pdf)
  
  ‚Ä¢ [Certificat Python - La visualisation des donn√©es](./Certificats/CertificatDaccomplissement_Python_La_visualisation_des_donnees.pdf)
  
  ‚Ä¢ [Certificat Python - Niveau avanc√©](./Certificats/CertificatDaccomplissement_Python_Niveau_avance.pdf)
  
  ‚Ä¢ [Certificat Pandas pour la data science](./Certificats/CertificatDaccomplissement_pandas%20_pour%20_la_%20data_science.pdf)

  ‚Ä¢ [Scrum Fundamentals Certified](./Certificats/ScrumFundamentalsCertified-MamoudouNdongo-1050242.pdf)
  


