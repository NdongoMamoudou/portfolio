# Data Science Portfolio - NDONGO Mamoudou 

Ce portfolio regroupe l'ensemble des projets que j'ai réalisés en science des données et en analyse de données dans le cadre de mes études, de mon apprentissage personnel et par passion. Il met également en avant mes réalisations, mes compétences et mes certifications, avec des mises à jour régulières pour refléter ma progression.

#### Email :  mamoudoundongo78@gmail.com

#### Linkedin : https://www.linkedin.com/in/mamoudou-ndongo/

## Réalisations

## Projets




<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/G_aosis1.png" alt="GP Colis Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/gp_colis">
          GP Colis - Gestion des Colis entre le Sénégal et la France
        </a>
      </strong>
      <p>
        **GP Colis** est une application web dédiée à la gestion et à la publication d'annonces pour l'envoi ou la réception de colis entre le Sénégal et la France. 
        Les utilisateurs peuvent publier des annonces, consulter celles des autres, et organiser des envois de colis en utilisant une interface conviviale et responsive.
      </p>
      <p><strong>Fonctionnalités principales :</strong> Création de comptes, publication d'annonces de colis, validation des informations, affichage dynamique des villes via API.</p>
      <p><strong>Technologies utilisées :</strong> React.js, Node.js, Axios, API REST, Nginx (Reverse Proxy), HTML5, CSS3.</p>
    </td>
  </tr>
</table>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/spam.PNG" alt="Icône d'email" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/Deep_Learning_pour_la_Classification_Binaire">
          Classification : Emails (Spam) et Cancer
        </a>
      </strong>
      <p>
        Ce dépôt regroupe deux projets exploitant des modèles de Deep Learning pour résoudre des problématiques de classification binaire. 
        Le premier projet porte sur la classification d'emails, avec pour objectif d'identifier si un message est un spam ou non. 
        Le second projet se concentre sur la classification médicale, visant à prédire si une personne est atteinte de cancer.
      </p>
    </td>
  </tr>
</table>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/finance.PNG" alt="Icône Marketing" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/analyse-donnees_fraude-marketing">
          Analyse des Comportements d'Achat des Clients - Campagne Marketing
        </a>
      </strong>
      <p>
        Ce projet explore les comportements d'achat des clients d'une entreprise à partir des données de campagnes marketing. L'objectif est de 
        réaliser une analyse exploratoire des données (EDA) pour mieux comprendre les habitudes d'achat des clients, nettoyer et préparer les 
        données, puis appliquer une segmentation basée sur les revenus et les dépenses. Cette analyse est présentée sous forme d'un tableau de bord 
        interactif développé avec Streamlit, permettant d'interagir facilement avec les insights obtenus. 
      </p>
    </td>
  </tr>
</table>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/web_scraping.PNG" alt="web scraping" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/WebScrapingCollection">
          Web Scraping Collection
        </a>
      </strong>
      <p>
        Un projet d'extraction automatisée de données à partir de sites web. Il permet de collecter des informations structurées (produits, prix, articles, etc.) 
        de manière rapide et efficace pour des analyses ou surveiller des données en temps réel.
      </p>
      <p><strong>Technologies utilisées :</strong> Python, BeautifulSoup, scrapy, Selenium, Requests, Pandas.</p>
    </td>
  </tr>
</table>

<table style="width: 100%; table-layout: fixed;">
  <tr>
    <td style="width: 50%; text-align: center;">
      <img src="Images/sismic_analysis.png" alt="Analyse Sismique Screenshot" style="width: 100%; max-width: 300px; height: auto;">
    </td>
    <td style="width: 50%;">
      <strong>
        <a href="https://github.com/NdongoMamoudou/seismic-data-analysis">
          Analyse et Traitement des Données Sismiques avec Hadoop, Hive et Spark
        </a>
      </strong>
      <p>
        **Ce projet Big Data** a pour objectif de traiter et analyser de grands volumes de données sismiques 
        en utilisant un environnement distribué basé sur **Hadoop, Hive et Spark**. L’objectif principal est 
        de détecter des événements sismiques et de comprendre les tendances sismiques sur différentes périodes.
      </p>
      <p><strong>Fonctionnalités principales :</strong></p>
      <ul>
        <li>Déploiement d’un environnement **Docker** avec **Hadoop, Hive et Spark**</li>
        <li>Importation et traitement des données sismiques stockées sur **HDFS**</li>
        <li>Nettoyage et transformation des données avec **Spark**</li>
        <li>Analyse des événements sismiques et détection de tendances</li>
        <li>Intégration de **Kafka** et **Spark Streaming** pour les analyses temporelles</li>
        <li>Possibilité d’ajouter une interface de visualisation avec **Apache Superset** ou **Echarts**</li>
      </ul>
      <p><strong>Technologies utilisées :</strong> Docker, Hadoop (HDFS), Hive, Spark, Kafka, Apache Superset, Echarts.</p>
    </td>
  </tr>
</table>






                                                  
## Microprojets

## Compétences de base

  • Methodologies: Machine Learning, Deep Learning, Statistics, Big Data Analytics, Web scraping
  
  • Languages: Python (Pandas, Numpy, Scikit-Learn, Scipy, Keras, Matplotlib, BeautifulSoup, scrapy , Selenium, ), SQL, C++
  
  • Tools: MySQL, Tableau, Git, PySpark, Amazon Web Services (AWS), Flask, MS Excel
  

## Certificats

  • [Certificat Python - La visualisation des données](./Certificats/CertificatDaccomplissement_Python_La_visualisation_des_donnees.pdf)
  
  • [Certificat Python - La visualisation des données](./Certificats/CertificatDaccomplissement_Python_La_visualisation_des_donnees.pdf)
  
  • [Certificat Python - Niveau avancé](./Certificats/CertificatDaccomplissement_Python_Niveau_avance.pdf)
  
  • [Certificat Pandas pour la data science](./Certificats/CertificatDaccomplissement_pandas%20_pour%20_la_%20data_science.pdf)

  • [Scrum Fundamentals Certified](./Certificats/ScrumFundamentalsCertified-MamoudouNdongo-1050242.pdf)
  


